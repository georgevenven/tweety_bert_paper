{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import torch \n",
    "import json\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "sys.path.append(\"src\")\n",
    "os.chdir('/home/george-vengrovski/Documents/projects/tweety_bert_paper')\n",
    "\n",
    "from data_class import SongDataSet_Image, CollateFunction\n",
    "from model import TweetyBERT\n",
    "from analysis import plot_umap_projection\n",
    "from utils import detailed_count_parameters, load_weights, load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from data_class import SongDataSet_Image\n",
    "\n",
    "train_dir = \"/home/george-vengrovski/Documents/projects/tweety_bert_paper/files/llb3_train\"\n",
    "test_dir = \"/home/george-vengrovski/Documents/projects/tweety_bert_paper/files/llb3_test\"\n",
    "\n",
    "train_dataset = SongDataSet_Image(train_dir, num_classes=21, psuedo_labels_generated=False)\n",
    "test_dataset = SongDataSet_Image(test_dir, num_classes=21, psuedo_labels_generated=False)\n",
    "\n",
    "collate_fn = CollateFunction(segment_length=1000)  # Adjust the segment length if needed\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=4, shuffle=True, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "import pickle\n",
    "\n",
    "reductions_dims = 2\n",
    "plot_figure = True\n",
    "\n",
    "list_of_data = []\n",
    "list_of_ground_truth = []\n",
    "\n",
    "for i, (data, ground_truth_label, _) in enumerate(test_loader):\n",
    "    # Remove channel dimension (used for convolutional layers)\n",
    "    data = data[:, 0, :, :]\n",
    "    # Permute dimensions\n",
    "    data = data.permute(0, 2, 1)\n",
    "    # Convert labels to indices\n",
    "    ground_truth_label = ground_truth_label.argmax(-1)\n",
    "    # Convert to numpy arrays\n",
    "    data = data.cpu().numpy()\n",
    "    ground_truth_label = ground_truth_label.cpu().numpy()\n",
    "    # Reshape labels\n",
    "    ground_truth_label = ground_truth_label.reshape(-1, 1)\n",
    "    data = data.reshape(-1, 1 * 196)\n",
    "    # Append to lists\n",
    "    list_of_data.append(data)\n",
    "    list_of_ground_truth.append(ground_truth_label)\n",
    "\n",
    "    # Break the loop after processing 101 batches\n",
    "    if i > 100:\n",
    "        break\n",
    "\n",
    "# Concatenate the lists\n",
    "list_of_data = np.concatenate(list_of_data, axis=0)\n",
    "list_of_ground_truth = np.concatenate(list_of_ground_truth, axis=0)\n",
    "\n",
    "# Randomly sample 10,000 points\n",
    "sample_indices = np.random.choice(list_of_data.shape[0], 10000, replace=False)\n",
    "list_of_data_sampled = list_of_data[sample_indices]\n",
    "list_of_ground_truth_sampled = list_of_ground_truth[sample_indices]\n",
    "\n",
    "# Load color map data\n",
    "file_path = \"/home/george-vengrovski/Documents/projects/tweety_bert_cluster/project/category_colors_llb3.pkl\"\n",
    "with open(file_path, 'rb') as file:\n",
    "    color_map_data = pickle.load(file)\n",
    "\n",
    "# Map labels to colors\n",
    "label_to_color = {label: tuple(color) for label, color in color_map_data.items()}\n",
    "\n",
    "# Prepare colors for plotting points\n",
    "colors_for_points = []\n",
    "for label_row in list_of_ground_truth_sampled:\n",
    "    if label_row.ndim > 0:\n",
    "        row_colors = [label_to_color[int(lbl)] for lbl in label_row]\n",
    "        avg_color = np.mean(row_colors, axis=0)\n",
    "    else:\n",
    "        avg_color = label_to_color[int(label_row)]\n",
    "    colors_for_points.append(avg_color)\n",
    "\n",
    "# Initialize and apply PCA\n",
    "pca = PCA(n_components=reductions_dims, random_state=42)\n",
    "embedding_outputs = pca.fit_transform(list_of_data_sampled)\n",
    "\n",
    "# Plot if conditions are met\n",
    "if reductions_dims == 2 and plot_figure == True:\n",
    "    fig = plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(embedding_outputs[:, 0], embedding_outputs[:, 1], s=5, c=colors_for_points)\n",
    "    plt.title('PCA projection of the Spectograms', fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from linear_probe import LinearProbeModel, LinearProbeTrainer\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "classifier_model = LinearProbeModel(num_classes=21, model_type=\"pca\", model=None, freeze_layers=None, layer_num=None, layer_id=None, classifier_dims=2)\n",
    "classifier_model = classifier_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = LinearProbeTrainer(model=classifier_model, train_loader=train_loader, test_loader=test_loader, device=device, lr=1e-3, plotting=True, batches_per_eval=100, desired_total_batches=1, patience=4)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from linear_probe import ModelEvaluator\n",
    "\n",
    "evaluator = ModelEvaluator(classifier_model, test_loader, use_tqdm=True)\n",
    "class_frame_error_rates, total_frame_error_rate = evaluator.validate_model_multiple_passes(num_passes=1, max_batches=1250)\n",
    "evaluator.save_results(class_frame_error_rates, total_frame_error_rate, 'results')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
